{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9097,"sourceType":"datasetVersion","datasetId":491}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Why Checking DOIs via API is the ‚ÄúSilver Bullet‚Äù for AI Detection\nChecking References, specifically through their Digital Object Identifiers (DOIs), is arguably the most definitive method to catch AI hallucinations. Large Language Models (LLMs) like ChatGPT often generate plausible-sounding citations that do not actually exist.\n\nHere is why the Python + doi.org Content Negotiation method is superior:\n\n-  Deterministic Accuracy (Binary Result)\nUnlike analyzing writing style or ‚Äúperplexity‚Äù scores‚Äîwhich are probabilistic and prone to false positives‚Äîa DOI check is binary. A DOI either exists in the global registry, or it doesn‚Äôt.\n\nResult: 404 Not Found = 100% Fake Reference.\n\n - Detecting ‚ÄúStolen‚Äù DOIs\nAI sometimes hallucinates by taking a real DOI from an unrelated paper and attaching it to a fake citation.\n\n- The Fix: By retrieving the metadata (JSON) directly from the source, you can compare the actual title in the database against the title listed in the suspicious paper. If the paper claims to be about ‚ÄúEconomics‚Äù but the DOI resolves to ‚ÄúMarine Biology,‚Äù it is undeniable proof of AI generation.\n-  Global Coverage (Not Just One Publisher)\nBy querying the central doi.org resolver rather than specific publisher APIs (like Elsevier or Wiley), this method covers all academic content.\n\nEfficiency: It handles redirects automatically, finding the metadata whether the paper is hosted on Crossref, DataCite, or mEDRA.\n- . Scalability and Automation\nManually clicking 50 links is tedious. This Python script allows for batch processing. You can feed it a list of 100 references and receive a full audit report in seconds, making it perfect for editors, professors, or automated quality control systems.","metadata":{}},{"cell_type":"markdown","source":"In this section, we proved that this is an efficient way to find if a paper is valid or not. ","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport time","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\n\ndef verify_doi_validity(doi_input):\n    \"\"\"\n    Checks if a DOI exists by querying the doi.org resolver directly.\n    Returns detailed metadata if valid, or an error status if invalid.\n    \"\"\"\n    # Clean the input to ensure we only have the DOI string\n    clean_doi = doi_input.replace(\"https://doi.org/\", \"\").replace(\"http://doi.org/\", \"\")\n    \n    url = f\"https://doi.org/{clean_doi}\"\n    \n    headers = {\n        \"Accept\": \"application/vnd.citationstyles.csl+json\"\n    }\n\n    try:\n        response = requests.get(url, headers=headers, allow_redirects=True, timeout=10)\n        \n        if response.status_code == 200:\n            try:\n                data = response.json()\n            except ValueError:\n                return {\"status\": \"Error\", \"details\": \"Response was not valid JSON.\"}\n            \n            # 1. Extracting Title\n            title = data.get('title', 'N/A')\n            if isinstance(title, list) and len(title) > 0:\n                title = title[0]\n            \n            # 2. Extracting Journal Name (Container Title)\n            journal = data.get('container-title', 'N/A')\n            if isinstance(journal, list) and len(journal) > 0:\n                journal = journal[0]\n\n            # 3. Extracting First Author's Last Name\n            author_lastname = \"N/A\"\n            if 'author' in data and len(data['author']) > 0:\n                # We take the first author in the list\n                author_lastname = data['author'][0].get('family', 'N/A')\n\n            return {\n                \"status\": \"Valid\",\n                \"real_title\": title,\n                \"journal\": journal,\n                \"first_author\": author_lastname\n            }\n            \n        elif response.status_code == 404:\n            return {\"status\": \"Invalid\", \"details\": \"DOI not found\"}\n        else:\n            return {\"status\": \"Error\", \"details\": f\"HTTP Code: {response.status_code}\"}\n\n    except Exception as e:\n        return {\"status\": \"Connection Error\", \"details\": str(e)}\n\n# --- Usage Example ---\n\ndoi_list_to_check = [\n    \"10.1038/nature123\",            # Fake\n    \"10.1007/s10701-005-9016-x\",    # Valid (Physics paper)\n    \"10.1016/j.jbi.2008.04.002\",    # Valid (Bioinformatics paper)\n    \"10.1126/science.fake.999\"      # Fake\n]\n\n# Header format for the table\nprint(f\"{'DOI':<27} | {'Status':<8} | {'Author':<15} | {'Journal':<20} | {'Real Title'}\")\nprint(\"-\" * 110)\n\nfor doi in doi_list_to_check:\n    result = verify_doi_validity(doi)\n    \n    if result['status'] == \"Valid\":\n        # Clean and shorten strings for table display\n        author = str(result['first_author'])[:15]\n        journal = str(result['journal'])[:20]\n        title = str(result['real_title'])[:35] + \"...\"\n        \n        print(f\"{doi:<27} | {result['status']:<8} | {author:<15} | {journal:<20} | {title}\")\n    else:\n        # For errors, we just print the details in the last column\n        print(f\"{doi:<27} | {result['status']:<8} | {'-':<15} | {'-':<20} | {result.get('details', '-')}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# for csv files","metadata":{}},{"cell_type":"code","source":"#  Define the extraction function\ndef extract_dois_from_text(text):\n    \"\"\"\n    Scans a text string for DOIs using regex.\n    Returns a list of unique DOIs found, or an empty list.\n    \"\"\"\n    # The standard DOI regex\n    doi_pattern = r'\\b(10\\.\\d{4,9}/[-._;()/:a-zA-Z0-9]+)\\b'\n    # we can extend \\d{4,9} mybe capture more \n    \n    if not isinstance(text, str):\n        return []\n        \n    matches = re.findall(doi_pattern, text)\n    \n    # Clean up trailing punctuation (like a period at the end of a sentence)\n    unique_dois = set()\n    for doi in matches:\n        clean = doi.rstrip(\".,)\")\n        unique_dois.add(clean)\n        \n    return list(unique_dois)\n\n#  Apply it to the dataframe\nprint(\"Extracting DOIs from 'paper_text' column... this might take a moment.\")\ndf['extracted_dois'] = df['paper_text'].apply(extract_dois_from_text)\n\n#  Create a count column just to see how many we found per paper\ndf['doi_count'] = df['extracted_dois'].apply(len)\n\n# 4. Filter to show only papers where we actually found DOIs\npapers_with_dois = df[df['doi_count'] > 0].copy()\n\nprint(f\"\\nProcessing Complete.\")\nprint(f\"Total Papers Scanned: {len(df)}\")\nprint(f\"Papers containing DOIs: {len(papers_with_dois)}\")\n\n# Show a preview of the results\nif len(papers_with_dois) > 0:\n    print(\"\\n--- Preview of Papers with Extracted DOIs ---\")\n    # We select just the ID, Year, Title, and the list of DOIs found\n    display_cols = ['id', 'year', 'title', 'extracted_dois']\n    try:\n        display(papers_with_dois[display_cols].head())\n    except NameError:\n        print(papers_with_dois[display_cols].head())\nelse:\n    print(\"No DOIs found. Note: Older papers (1987-1990s) often didn't print DOIs in their bibliographies.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Your provided verification function\ndef verify_doi_validity(doi_input):\n    clean_doi = doi_input.replace(\"https://doi.org/\", \"\").replace(\"http://doi.org/\", \"\")\n    url = f\"https://doi.org/{clean_doi}\"\n    headers = {\"Accept\": \"application/vnd.citationstyles.csl+json\"}\n\n    try:\n        response = requests.get(url, headers=headers, allow_redirects=True, timeout=10)\n        \n        if response.status_code == 200:\n            try:\n                data = response.json()\n            except ValueError:\n                return {\"status\": \"Error\", \"details\": \"Response was not valid JSON.\"}\n            \n            title = data.get('title', 'N/A')\n            if isinstance(title, list) and len(title) > 0: title = title[0]\n            \n            journal = data.get('container-title', 'N/A')\n            if isinstance(journal, list) and len(journal) > 0: journal = journal[0]\n\n            author_lastname = \"N/A\"\n            if 'author' in data and len(data['author']) > 0:\n                author_lastname = data['author'][0].get('family', 'N/A')\n\n            return {\n                \"validity\": \"Valid\",\n                \"meta_title\": title,\n                \"meta_journal\": journal,\n                \"meta_author\": author_lastname,\n                \"details\": \"OK\"\n            }\n        elif response.status_code == 404:\n            return {\"validity\": \"Invalid\", \"meta_title\": \"-\", \"meta_journal\": \"-\", \"meta_author\": \"-\", \"details\": \"DOI Not Found\"}\n        else:\n            return {\"validity\": \"Error\", \"meta_title\": \"-\", \"meta_journal\": \"-\", \"meta_author\": \"-\", \"details\": f\"HTTP {response.status_code}\"}\n\n    except Exception as e:\n        return {\"validity\": \"Conn Error\", \"meta_title\": \"-\", \"meta_journal\": \"-\", \"meta_author\": \"-\", \"details\": str(e)}\n\n\n# Iterate through the papers and check their DOIs\n\nresults_list = []\n\n# LIMITER: We only check the first 5 papers for this demo to save time.\n# Remove .head(5) to run on all papers.\npapers_to_check = papers_with_dois.head(5)\n\nprint(f\"Starting verification on {len(papers_to_check)} papers...\")\n\nfor index, row in papers_to_check.iterrows():\n    paper_id = row['id']\n    paper_year = row['year']\n    extracted_dois = row['extracted_dois']\n    \n    print(f\"Processing Paper ID {paper_id} ({len(extracted_dois)} DOIs found)...\")\n    \n    for doi in extracted_dois:\n        # Run the verification API\n        res = verify_doi_validity(doi)\n        \n        # Save the result in a structured way\n        results_list.append({\n            \"Paper_ID\": paper_id,\n            \"Paper_Year\": paper_year,\n            \"Checked_DOI\": doi,\n            \"Status\": res['validity'],\n            \"Real_Author\": res['meta_author'],\n            \"Real_Journal\": res['meta_journal'],\n            \"Real_Title\": res['meta_title'],\n            \"Notes\": res['details']\n        })\n        \n        # Be polite to the API server, sleep a tiny bit\n        time.sleep(0.2)\n\n# Convert results to a DataFrame for nice display\nverification_df = pd.DataFrame(results_list)\n\nprint(\"\\n--- Verification Complete ---\")\n\n# Display valid vs invalid counts\nprint(verification_df['Status'].value_counts())\n\nprint(\"\\n--- Detailed Results Table ---\")\n# Displaying in a nice clean format\ndisplay_cols = ['Paper_ID', 'Checked_DOI', 'Status', 'Real_Author', 'Real_Journal']\ntry:\n    display(verification_df[display_cols])\nexcept NameError:\n    print(verification_df[display_cols])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Gradio Mini App","metadata":{}},{"cell_type":"code","source":"import gradio as gr\nimport re\nimport requests\nimport pandas as pd\n\n# --- API Helper Function ---\ndef get_api_data(doi):\n    \"\"\"\n    Fetches official metadata (Title, Year) from Crossref API.\n    \"\"\"\n    if not doi:\n        return \"-\", \"-\"\n        \n    try:\n        url = f\"https://api.crossref.org/works/{doi}\"\n        # Polite User-Agent to avoid being blocked\n        headers = {\"User-Agent\": \"ResearchParser/2.0 (mailto:test@example.com)\"}\n        \n        response = requests.get(url, headers=headers, timeout=5)\n        \n        if response.status_code == 200:\n            data = response.json()['message']\n            \n            # Extract Official Title\n            api_title = data.get('title', ['-'])[0]\n            \n            # Extract Official Year\n            date_parts = data.get('issued', {}).get('date-parts', [[None]])\n            api_year = str(date_parts[0][0]) if date_parts[0][0] else \"-\"\n            \n            return api_title, api_year\n        else:\n            return \"Error Fetching\", \"Error\"\n    except:\n        return \"Connection Failed\", \"Error\"\n\n# --- Local Text Extraction Function ---\ndef extract_local_info(text):\n    \"\"\"\n    Attempts to parse Title and Year directly from the raw input text strings.\n    \"\"\"\n    # 1. Find DOI\n    doi_match = re.search(r'\\b(10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)', text, re.IGNORECASE)\n    doi = doi_match.group(1).rstrip('.') if doi_match else None\n    \n    # 2. Find Title (Heuristic: Look for text inside quotes)\n    # Matches both standard quotes \"\" and smart quotes ‚Äú‚Äù\n    title_match = re.search(r'[‚Äú\"](.*?)[‚Äù\"]', text)\n    local_title = title_match.group(1) if title_match else \"Not found in quotes\"\n    \n    # 3. Find Year (Heuristic: Last 4-digit number starting with 19 or 20)\n    years = re.findall(r'\\b(19|20)\\d{2}\\b', text)\n    local_year = years[-1] if years else \"-\"\n    \n    # Cleanup: If the found year is actually part of the DOI (e.g. 10.1016), ignore it\n    if local_year and doi and local_year in doi:\n         local_year = \"-\"\n\n    return doi, local_title, local_year\n\n# --- Main Processing Logic ---\ndef process_references(text):\n    if not text:\n        return pd.DataFrame()\n\n    # Split text based on reference numbers like [1], [2]\n    raw_refs = re.split(r'(\\[\\d+\\])', text)\n    \n    parsed_data = []\n    current_id = \"\"\n    \n    for chunk in raw_refs:\n        chunk = chunk.strip()\n        if not chunk: continue\n        \n        # Identify Reference ID (e.g., [1])\n        if re.match(r'\\[\\d+\\]', chunk):\n            current_id = chunk\n        else:\n            # It is the reference text content\n            full_text = chunk.replace('\\n', ' ')\n            \n            # 1. Extract from Text (Local)\n            doi, local_title, local_year = extract_local_info(full_text)\n            \n            # 2. Extract from API (Web)\n            if doi:\n                api_title, api_year = get_api_data(doi)\n            else:\n                api_title, api_year = \"-\", \"-\"\n\n            # 3. Append to list for the DataFrame\n            parsed_data.append([\n                current_id, \n                doi if doi else \"-\", \n                local_title,  # Extracted from text\n                api_title,    # Extracted from API\n                local_year,   # Extracted from text\n                api_year      # Extracted from API\n            ])\n\n    # Create DataFrame\n    df = pd.DataFrame(parsed_data, columns=[\n        \"Ref ID\", \n        \"DOI\", \n        \"Title (From Text)\", \n        \"Title (From API)\", \n        \"Year (Text)\", \n        \"Year (API)\"\n    ])\n    return df\n\n# --- Gradio UI ---\n\nwith gr.Blocks(title=\"Smart Citation Comparator\") as demo:\n    gr.Markdown(\"#  Smart Reference Parser & Comparator\")\n    gr.Markdown(\"Paste your bibliography below. The system will extract data from your **text** (Local) and compare it with the **Crossref Database** (API).\")\n    \n    with gr.Row():\n        # Left: Input\n        with gr.Column(scale=1):\n            input_text = gr.Textbox(\n                lines=10, \n                label=\"Input Bibliography\", \n                placeholder=\"[1] Author Name, ‚ÄúPaper Title Here‚Äù, Journal, 2023, doi:10.1000/xyz...\"\n            )\n            btn = gr.Button(\"Analyze & Compare\", variant=\"primary\")\n        \n        # Right: Output\n        with gr.Column(scale=3):\n            output_table = gr.Dataframe(\n                label=\"Comparison Table\",\n                headers=[\"Ref ID\", \"DOI\", \"Title (From Text)\", \"Title (From API)\", \"Year (Text)\", \"Year (API)\"],\n                interactive=False,\n                wrap=True\n            )\n\n    btn.click(fn=process_references, inputs=input_text, outputs=output_table)\n\nif __name__ == \"__main__\":\n    demo.launch()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:14:07.242478Z","iopub.execute_input":"2025-12-01T08:14:07.242837Z","iopub.status.idle":"2025-12-01T08:14:12.870004Z","shell.execute_reply.started":"2025-12-01T08:14:07.242813Z","shell.execute_reply":"2025-12-01T08:14:12.868902Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://93e71b6e569ba3f5cf.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://93e71b6e569ba3f5cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"# second app","metadata":{}},{"cell_type":"code","source":"import gradio as gr\nimport re\nimport requests\nimport pandas as pd\n\n# --- CONFIGURATION: Suspicious Patterns ---\n# Known \"Tortured Phrases\" often used by AI paraphrasing tools\nTORTURED_PHRASES = [\n    \"counterfeit consciousness\", # instead of Artificial Intelligence\n    \"colossal information\",      # instead of Big Data\n    \"many-sided\",                # instead of multifaceted\n    \"random access memory\",      # usually fine, but sometimes used weirdly in context\n    \"sedentary phone\",           # instead of mobile phone\n    \"creepie-crawlie\",           # instead of bug/insect in bio papers\n    \"solar module\",              # sometimes used for 'sun' generally\n    \"flagitious\",                # archaic word often used by spinners\n]\n\n# List of highly trusted publishers (simplistic whitelist)\nTRUSTED_PUBLISHERS = [\n    \"IEEE\", \"Elsevier\", \"Springer\", \"Wiley\", \"ACM\", \"Nature\", \"Science\", \n    \"Taylor & Francis\", \"Sage\", \"Oxford University Press\", \"Cambridge University Press\"\n]\n\n# --- API Helper Function ---\ndef get_api_data(doi):\n    if not doi:\n        return \"-\", \"-\", \"-\"\n        \n    try:\n        url = f\"https://api.crossref.org/works/{doi}\"\n        headers = {\"User-Agent\": \"ResearchParser/3.0 (mailto:test@example.com)\"}\n        \n        response = requests.get(url, headers=headers, timeout=5)\n        \n        if response.status_code == 200:\n            data = response.json()['message']\n            \n            api_title = data.get('title', ['-'])[0]\n            publisher = data.get('publisher', '-')\n            \n            date_parts = data.get('issued', {}).get('date-parts', [[None]])\n            api_year = str(date_parts[0][0]) if date_parts[0][0] else \"-\"\n            \n            return api_title, api_year, publisher\n        else:\n            return \"Error Fetching\", \"Error\", \"Unknown\"\n    except:\n        return \"Connection Failed\", \"Error\", \"Unknown\"\n\n# --- Risk Analysis Function ---\ndef analyze_risk(title, publisher):\n    flags = []\n    score = 0\n    \n    # Check 1: Tortured Phrases in Title\n    if title and title != \"-\":\n        lower_title = title.lower()\n        for phrase in TORTURED_PHRASES:\n            if phrase in lower_title:\n                flags.append(f\"Suspicious Phrase: '{phrase}'\")\n                score += 3\n                # artirary \n\n    # Check 2: Title Length (Too short titles are suspicious)\n    if title and len(title) < 15 and title != \"-\":\n         flags.append(\"Title too short\")\n         score += 1\n\n    # Check 3: Publisher Analysis\n    if publisher == \"-\" or publisher == \"Unknown\":\n        flags.append(\"Unknown Publisher\")\n        score += 1\n    else:\n        # Check if publisher contains trusted keywords\n        is_trusted = any(tp.lower() in publisher.lower() for tp in TRUSTED_PUBLISHERS)\n        if not is_trusted:\n            flags.append(\"Niche/Unknown Publisher\") # Not necessarily bad, but worth noting\n            score += 0.5\n\n    # Determine Level\n    if score >= 3:\n        return \"üî¥ HIGH RISK\", \", \".join(flags)\n    elif score >= 1:\n        return \"üü° MODERATE\", \", \".join(flags)\n    else:\n        return \"üü¢ LOW\", \"Looks Standard\"\n\n# --- Local Extraction ---\ndef extract_local_info(text):\n    doi_match = re.search(r'\\b(10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)', text, re.IGNORECASE)\n    doi = doi_match.group(1).rstrip('.') if doi_match else None\n    \n    title_match = re.search(r'[‚Äú\"](.*?)[‚Äù\"]', text)\n    local_title = title_match.group(1) if title_match else \"Not found in quotes\"\n    \n    years = re.findall(r'\\b(19|20)\\d{2}\\b', text)\n    local_year = years[-1] if years else \"-\"\n    \n    if local_year and doi and local_year in doi:\n         local_year = \"-\"\n\n    return doi, local_title, local_year\n\n# --- Main Logic ---\ndef process_references(text):\n    if not text:\n        return pd.DataFrame()\n\n    raw_refs = re.split(r'(\\[\\d+\\])', text)\n    parsed_data = []\n    current_id = \"\"\n    \n    for chunk in raw_refs:\n        chunk = chunk.strip()\n        if not chunk: continue\n        \n        if re.match(r'\\[\\d+\\]', chunk):\n            current_id = chunk\n        else:\n            full_text = chunk.replace('\\n', ' ')\n            \n            # 1. Local Extract\n            doi, local_title, local_year = extract_local_info(full_text)\n            \n            # 2. API Extract\n            if doi:\n                api_title, api_year, publisher = get_api_data(doi)\n            else:\n                api_title, api_year, publisher = \"-\", \"-\", \"-\"\n\n            # 3. Analyze Risk (Using API Title preferably, otherwise Local)\n            target_title = api_title if api_title != \"-\" else local_title\n            risk_level, risk_details = analyze_risk(target_title, publisher)\n\n            parsed_data.append([\n                current_id, \n                doi if doi else \"-\", \n                api_title, \n                publisher,\n                risk_level,\n                risk_details\n            ])\n\n    df = pd.DataFrame(parsed_data, columns=[\n        \"ID\", \"DOI\", \"Official Title\", \"Publisher\", \"Risk Level\", \"Risk Details\"\n    ])\n    return df\n\n# --- Gradio UI ---\nwith gr.Blocks(title=\"Fake Paper Detector\") as demo:\n    gr.Markdown(\"# Advanced Citation & Risk Analyzer\")\n    gr.Markdown(\"Checks for: **Tortured Phrases** (AI generation indicators) and **Publisher Credibility**.\")\n    \n    with gr.Row():\n        with gr.Column(scale=1):\n            input_text = gr.Textbox(lines=8, label=\"Input References\", placeholder=\"Paste references here...\")\n            btn = gr.Button(\"Analyze Risks\", variant=\"primary\")\n        \n        with gr.Column(scale=3):\n            output_table = gr.Dataframe(\n                label=\"Risk Analysis Report\",\n                headers=[\"ID\", \"DOI\", \"Official Title\", \"Publisher\", \"Risk Level\", \"Risk Details\"],\n                interactive=False,\n                wrap=True\n            )\n\n    btn.click(fn=process_references, inputs=input_text, outputs=output_table)\n\nif __name__ == \"__main__\":\n    demo.launch()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# fake refrence using names ","metadata":{}},{"cell_type":"code","source":"import gradio as gr\nimport re\nimport requests\nimport pandas as pd\nfrom difflib import SequenceMatcher\n\n# --- Helper: Calculate Text Similarity ---\ndef similarity_score(a, b):\n    if not a or not b: return 0.0\n    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n\n# --- API Helper Function ---\ndef search_crossref(doi=None, title_query=None):\n    \"\"\"\n    Returns: (Title, Year, List of Family Names, Source Note)\n    \"\"\"\n    try:\n        headers = {\"User-Agent\": \"AuthCheck/5.0 (mailto:test@example.com)\"}\n        data = None\n        note = \"\"\n\n        if doi:\n            url = f\"https://api.crossref.org/works/{doi}\"\n            response = requests.get(url, headers=headers, timeout=5)\n            if response.status_code == 200:\n                data = response.json()['message']\n                note = \"Found via DOI\"\n        \n        elif title_query:\n            url = \"https://api.crossref.org/works\"\n            # Request top 1 result\n            params = {'query.bibliographic': title_query, 'rows': 1}\n            response = requests.get(url, headers=headers, params=params, timeout=5)\n            if response.status_code == 200:\n                items = response.json()['message']['items']\n                if items:\n                    data = items[0]\n                    note = f\"Found via Title Search (DOI: {data.get('DOI', '-')})\"\n\n        if data:\n            api_title = data.get('title', [''])[0]\n            \n            # Extract Authors (List of family names)\n            authors_raw = data.get('author', [])\n            # We specifically get 'family' name because 'given' names vary (J. vs John)\n            api_authors = [a.get('family', '') for a in authors_raw if 'family' in a]\n            \n            return api_title, api_authors, note\n            \n        return None, [], \"Not Found\"\n\n    except Exception as e:\n        return None, [], f\"Error: {str(e)}\"\n\n# --- Local Extraction ---\ndef extract_local_info(text):\n    # 1. Find DOI\n    doi_match = re.search(r'\\b(10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)', text, re.IGNORECASE)\n    doi = doi_match.group(1).rstrip('.') if doi_match else None\n    \n    # 2. Find Title (Text inside quotes)\n    # Regex Explanation: Capture everything inside the first pair of quotes\n    title_match = re.search(r'[‚Äú\"](.*?)[‚Äù\"]', text)\n    local_title = title_match.group(1) if title_match else None\n    \n    # 3. Find Author (Heuristic: Everything BEFORE the opening quote)\n    # We assume format is: Author Names \"Title\" ...\n    local_author_str = \"Unknown\"\n    if title_match:\n        # Get the start index of the quote\n        quote_start = title_match.start()\n        # Slice text from 0 to quote_start\n        pre_title_text = text[:quote_start].strip()\n        # Remove trailing commas or periods\n        local_author_str = pre_title_text.rstrip('.,: ')\n    \n    return doi, local_title, local_author_str\n\n# --- Validation Logic ---\ndef check_author_match(local_str, api_authors_list):\n    \"\"\"\n    Checks if any of the official API authors appear in the local string.\n    \"\"\"\n    if not api_authors_list:\n        return \"‚ùì No Data\", False\n        \n    # Check if ANY official family name is present in the user's text\n    # We verify length > 2 to avoid matching short strings like \"Li\" or \"Ng\" incorrectly easily (optional safety)\n    found_authors = []\n    for auth in api_authors_list:\n        if auth.lower() in local_str.lower():\n            found_authors.append(auth)\n            \n    if found_authors:\n        return f\"‚úÖ Match ({', '.join(found_authors)})\", True\n    else:\n        # Create a string of expected authors for the error message\n        expected = \", \".join(api_authors_list[:3]) # Show max 3\n        return f\"‚ùå Mismatch (Expected: {expected}...)\", False\n\n# --- Main Processor ---\ndef verify_full_citation(text):\n    if not text:\n        return pd.DataFrame()\n\n    raw_refs = re.split(r'(\\[\\d+\\])', text)\n    results = []\n    current_id = \"?\"\n    \n    for chunk in raw_refs:\n        chunk = chunk.strip()\n        if not chunk: continue\n        \n        if re.match(r'\\[\\d+\\]', chunk):\n            current_id = chunk\n        else:\n            full_text = chunk.replace('\\n', ' ')\n            \n            # 1. Extract Local Data\n            doi, local_title, local_author_str = extract_local_info(full_text)\n            \n            api_title = \"-\"\n            api_authors = []\n            status_title = \"Unknown\"\n            status_author = \"Unknown\"\n            \n            # 2. Fetch Data (Strategy: DOI first, then Title)\n            if doi:\n                found_title, found_authors, note = search_crossref(doi=doi)\n            elif local_title:\n                found_title, found_authors, note = search_crossref(title_query=local_title)\n            else:\n                found_title, found_authors, note = None, [], \"Format Error\"\n\n            # 3. Verify Title\n            if found_title:\n                api_title = found_title\n                api_authors = found_authors\n                \n                # Calculate Similarity\n                if local_title:\n                    score = similarity_score(local_title, api_title) * 100\n                    if score > 80:\n                        status_title = \"‚úÖ Title Verified\"\n                    elif score > 50:\n                        status_title = f\"‚ö†Ô∏è Low Similarity ({int(score)}%)\"\n                    else:\n                        status_title = \"‚õî Title Mismatch\"\n                else:\n                    status_title = \"‚ö†Ô∏è No Local Title\"\n                    \n                # 4. Verify Author (Only if title was found)\n                status_author, is_author_ok = check_author_match(local_author_str, api_authors)\n                \n            else:\n                status_title = \"‚ùå Paper Not Found\"\n                status_author = \"-\"\n\n            results.append([\n                current_id,\n                local_title[:30] + \"...\" if local_title else \"-\", # Shorten for display\n                local_author_str[:20] + \"...\" if local_author_str else \"-\",\n                status_title,\n                status_author,\n                note\n            ])\n\n    df = pd.DataFrame(results, columns=[\n        \"ID\", \"Local Title\", \"Local Author\", \"Title Check\", \"Author Check\", \"Source\"\n    ])\n    return df\n\n# --- Gradio UI ---\nwith gr.Blocks(title=\"Full Citation Auditor\") as demo:\n    gr.Markdown(\"# üëÆ‚Äç‚ôÇÔ∏è Full Citation Auditor\")\n    gr.Markdown(\"Checks both **Title** AND **Author** validity.\")\n    gr.Markdown(\"1. Extracts Author & Title from your text.\\n2. Finds the official paper.\\n3. Compares if the Author matches the real paper.\")\n    \n    with gr.Row():\n        with gr.Column(scale=1):\n            input_text = gr.Textbox(\n                lines=10, \n                label=\"Paste References\", \n                placeholder=\"[1] Vaswani, A. \\\"Attention Is All You Need\\\". NIPS, 2017.\\n[2] Einstein, A. \\\"Deep Learning for Cats\\\". Fake Journal, 2024.\"\n            )\n            btn = gr.Button(\"Audit Citations\", variant=\"primary\")\n        \n        with gr.Column(scale=3):\n            output_table = gr.Dataframe(\n                label=\"Audit Report\",\n                headers=[\"ID\", \"Local Title\", \"Local Author\", \"Title Check\", \"Author Check\", \"Source\"],\n                interactive=False,\n                wrap=True\n            )\n\n    btn.click(fn=verify_full_citation, inputs=input_text, outputs=output_table)\n\nif __name__ == \"__main__\":\n    demo.launch()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T21:20:55.854478Z","iopub.execute_input":"2025-12-04T21:20:55.854774Z","iopub.status.idle":"2025-12-04T21:20:58.300844Z","shell.execute_reply.started":"2025-12-04T21:20:55.854732Z","shell.execute_reply":"2025-12-04T21:20:58.300191Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7861\nIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://85f0b15da706552cec.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://85f0b15da706552cec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":3}]}